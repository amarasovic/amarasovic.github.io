---
classes: wide
layout: single
author_profile: true
date:   2020-12-05 22:15:29 -0800
---

Please feel welcome to use my slides with proper attribution.

* <a href="https://docs.google.com/presentation/d/1ifE2ocHHEgYuyQoyMtsVeWuTp_3XOUYp3r709ITTiL0/edit?usp=sharing" style="color:navy">Challenges in Fostering (Dis)Trust in AI</a>

* <a href="https://docs.google.com/presentation/d/1Lr7F6c7wc2G5tRIOLwix39JfT5VNo3TAMVWEURhGl4Y/edit?usp=sharing" style="color:navy">Ingredients of Generative AI</a>

* <a href="https://docs.google.com/presentation/d/1AUBXarUkBpWM2pEWqAQXKSBl5-VQr1721xZ9e3l_4eE/edit?usp=sharing" style="color:navy">"We propose {insert an explainability method} to increase the trust of users in AI": What does this mean and how to go about it?</a>

* <a href="https://docs.google.com/presentation/d/14VjRIrhPd0r3nxPOTcPyXVc-Rziwtd46oUILXUqQ_Mg/edit?usp=sharing style=" style="color:navy">Self-Explaining for Intuitive Interaction with AI</a>

* <a href="/slides/invited_talk_few_shot.pdf" style="color:navy">Self-Explainability for Intuitive and Controllable Interaction: <b>On Reducing Human-Authored Free-Text Explanations for Training<b></a> 

* <a href="/slides/invited_talk_contrastive.pdf" style="color:navy">Contrastive Explanations of NLP Models</a> 

* <a href="/slides/invited_talk_explanation_selection.pdf" style="color:navy"><b>Explanation Selection</b> Through The Lens of <b>Free-Text</b> and <b>Contrastive Explanations</b></a> 

* <a href="/slides/invited_talk_uw_compling_vcr_desiderata.pdf" style="color:navy">Reflecting on Interpretability Desiderata with Visual Commonsense Reasoning</a> 

* <a href="/slides/ana_marasovic_woman_research_day.pdf" style="color:navy">Teaching Machines Language Understanding</a> 

* <a href="https://youtu.be/K9v-3UJ_syg" style="color:navy">Resolving Abstract Anaphors in Discourse: Uphill Battles with Neural Ranking Models and Automatic Data Extraction</a> 



